#!/bin/bash

set -e

cd `dirname "${0}"`

if [[ -n "${PFB_DEBUG}" ]]; then
    set -x
fi

# If there's not already an AWS profile or key set, and a 'pfb' profile is defined, use that
if [[ -z "${AWS_PROFILE}" && -z "${AWS_ACCESS_KEY_ID}" && -n $(aws configure list-profiles | grep '^pfb$') ]]; then
    AWS_PROFILE=pfb
fi

# Get DEV_USER variable for use in user-specific resources
DEV_USER=${DEV_USER:-$USER}
if [[ -z "${DEV_USER}" ]]; then
    echo "DEV_USER must be set in the environment"
fi

function usage() {
    echo -n \
         "Usage: $(basename "$0")

Build and pull container images using docker-compose

Runs django migrations

"
}

function check_database() {
    # Check if database is set up to continue

    max=21 # 1 minute
    counter=1
    while true
    do
        echo "Checking if database is up yet (try ${counter})..."
        set +e
        docker compose exec -T database psql postgresql://pfb:pfb@database/pfb -c 'select 1' >/dev/null 2>/dev/null
        status_check=$?
        if [ $status_check == 0 ]
        then
            echo "Connected to database successfully"
            break
        fi
        set -e
        if [[ ${counter} == "${max}" ]]
        then
            echo "Could not connect to database after some time"
            exit 1
        fi
        sleep 3
        (( counter++ ))
    done
}

function run_database_migrations() {
    docker compose up -d database
    check_database
    docker compose run --rm --entrypoint python3 django manage.py migrate --noinput
    docker compose run --rm --entrypoint python3 django manage.py collectstatic --noinput
    docker compose stop database
}

function run_data_fixtures() {
    docker compose up -d database
    check_database
    echo "*** Loading score metadata fixture..."
    docker compose run --rm --entrypoint python3 django manage.py loaddata analysis-score-metadata

    if [ $1 ]; then
        echo "*** Importing crash data..."
        docker compose run --rm --entrypoint python3 django manage.py import_crash_data

        # The sample analysis results fixture takes a few steps
        echo "*** Downloading sample analysis results fixture..."
        aws --profile pfb s3 sync --exclude "*" --include "sample_analysis_results.json.gz" \
            "s3://test-pfb-inputs/" src/django/pfb_analysis/fixtures/
        echo "*** Loading sample analysis results fixture..."
        docker compose run --rm --entrypoint python3 django manage.py loaddata sample_analysis_results
        echo "*** Copying S3 files for sample analysis results fixture into your bucket..."
        aws --profile pfb s3 sync --quiet \
            "s3://test-pfb-inputs/fixture_results_files/" \
            "s3://${DEV_USER}-pfb-storage-us-east-1/results/"
        aws --profile pfb s3 sync --quiet \
            "s3://test-pfb-inputs/fixture_neighborhood_boundaries/" \
            "s3://${DEV_USER}-pfb-storage-us-east-1/neighborhood_boundaries/"
    fi
    docker compose stop database
}

if [ "${BASH_SOURCE[0]}" = "${0}" ]
then
    if [ "${1:-}" = "--help" ]
    then
        usage
    else
        pushd ..

        docker compose build --pull database django angularjs analysis tilegarden django-q

        run_database_migrations
        if [ "${1:-}" = "--load-data" ]; then
            run_data_fixtures true
        else
            run_data_fixtures
        fi

        echo "Copying angular site to nginx"
        pushd "src/nginx"
        docker run --rm -i -v "${PWD}/srv/dist:/static-export/dist" pfb-angularjs \
               rsync -rlptDv --delete --exclude .gitkeep \
                 /opt/pfb/angularjs/dist /static-export/
        popd

        # Build the nginx container after building angularjs and copying the files, so
        # it includes them
        docker compose build --pull nginx

        popd
    fi
fi
